{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "655a535f",
   "metadata": {},
   "source": [
    "## Notebook 01: Environment, Reproducibility, and Quick Data Sanity\n",
    "\n",
    "### 1. Purpose and Project Introduction\n",
    "\n",
    "This notebook establishes the computational and conceptual baseline for the éclat research prototype. éclat is a research-grade prototype that combines LLM-based intent/emotion detection with structured verification and underwriting modules to study pause-aware, empathetic loan conversations. The goal is to provide a reproducible pipeline that: (1) generates synthetic datasets representative of small‑mid sized retail loan interactions (amounts in INR, configurable between 10k–100k rows for experiments), (2) demonstrates intent/emotion detection using lightweight LLM wrappers and embeddings, (3) provides deterministic baselines for verification and underwriter reasoning, and (4) produces explainable artifacts and audit trails for evaluation.\n",
    "\n",
    "Scope and datasets: the provided `prototype/generate_data.py` creates synthetic `data/raw/` CSVs intended for reproducible experiments. For quick reviews this notebook uses small samples when `DRY_RUN=True`; switch to `DRY_RUN=False` to run full dataset reads.\n",
    "\n",
    "Rationale: establishing a rigorous environment and manifest up front reduces replication friction for reviewers, ensures deterministic runs for experiments, and captures the minimal metadata required for audit and reproducibility. The notebook is intentionally guarded: computationally expensive or GPU-bound cells in later notebooks are gated by the `DRY_RUN` flag so reviewers can inspect narrative and small visualizations without triggering heavy compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a29c9f0",
   "metadata": {},
   "source": [
    "### 2. Goals:\n",
    "\n",
    "This notebook prepares the environment and artifacts required for the research suite. High-level goals: \n",
    "\n",
    "- Confirm environment and core libraries (so reviewers know which packages and versions were used).\n",
    "- Produce `artifacts/env.json`, `artifacts/versions.json`, and `artifacts/manifest.json` (these artifacts are the minimal reproducibility bundle).\n",
    "- Run quick deterministic reproducibility checks (numpy/pandas/torch seeds) to validate that RNG seeding produces repeatable results on this machine/configuration.\n",
    "- Provide clear instructions to reproduce the environment on Windows (venv) or Conda and to get plotting working for visual checks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d1792",
   "metadata": {},
   "source": [
    "### 3. Setup Constants & Flags\n",
    "\n",
    "This code cell sets the reproducibility `SEED`, the `DRY_RUN` boolean (default `True`), and root paths for artifacts and data. `DRY_RUN=True` prevents heavy compute and limits dataset reads to samples. To run full experiments, set `DRY_RUN=False` and ensure you have the required compute resources (see notebook headers for compute notes).\n",
    "\n",
    "**Why these settings matter:** deterministic experiments require a documented seed and consistent data paths. Using `DRY_RUN` lets reviewers verify logic and outputs without triggering long training or large-file I/O; when running full experiments, the same constants ensure comparable results across runs. The cell also demonstrates how to set environment variables for repeatability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1dcedfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T13:57:45.247484Z",
     "iopub.status.busy": "2025-12-17T13:57:45.247238Z",
     "iopub.status.idle": "2025-12-17T13:57:45.657616Z",
     "shell.execute_reply": "2025-12-17T13:57:45.656721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRY_RUN=True; SEED=42; ROOT=C:\\Users\\ADITI\\Desktop\\rhyl-projects\\eclat\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# Setup constants and flags\n",
    "DRY_RUN = True  # switch to False to run full dataset reads / heavy compute\n",
    "SEED = 42\n",
    "\n",
    "from pathlib import Path\n",
    "import os, sys, random, json, hashlib, shutil, subprocess, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path('.')  # project root\n",
    "ARTIFACTS = ROOT.joinpath('artifacts')\n",
    "DATA_DIR = ROOT.joinpath('data','raw')\n",
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Document DRY_RUN behaviour in the notebook output\n",
    "print(f'DRY_RUN={DRY_RUN}; SEED={SEED}; ROOT={ROOT.resolve()}')\n",
    "\n",
    "# Example: set env vars for reproducibility (powershell/cmd examples shown later)\n",
    "os.environ.setdefault('ECLAT_SEED', str(SEED))\n",
    "os.environ.setdefault('ECLAT_DRY_RUN', '1' if DRY_RUN else '0')\n",
    "\n",
    "# Small helper to write JSON artifacts\n",
    "def write_artifact(name, obj):\n",
    "    p = ARTIFACTS.joinpath(name)\n",
    "    with p.open('w', encoding='utf8') as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
    "    print('Wrote', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230249f",
   "metadata": {},
   "source": [
    "### 4. Environment discovery & disk / GPU checks\n",
    "\n",
    "This section prints environment details (Python executable, pip version, OS, CPU count), examines disk free space for common drives, and checks for available GPUs via `torch`. Results are saved to `artifacts/env.json`. The plotting cell below visualizes disk free space if `matplotlib` is available.\n",
    "\n",
    "Why: disk space and GPU availability are often overlooked causes of nondeterministic failures (e.g., interrupted installs, fallback CPU-only runs). Recording drive free space and GPU metadata helps diagnose environment-dependent failures later. We save these results so they can be archived with experiment outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a392be95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T13:57:45.661301Z",
     "iopub.status.busy": "2025-12-17T13:57:45.660862Z",
     "iopub.status.idle": "2025-12-17T13:57:48.146143Z",
     "shell.execute_reply": "2025-12-17T13:57:48.145089Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADITI\\AppData\\Local\\Temp\\ipykernel_3164\\3548146598.py:15: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  env['timestamp'] = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote artifacts\\env.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'python_executable': 'D:\\\\rhyl-envs\\\\eclat_venv\\\\Scripts\\\\python.exe',\n",
       " 'pip_version': 'pip 25.3 from D:\\\\rhyl-envs\\\\eclat_venv\\\\Lib\\\\site-packages\\\\pip (python 3.13)',\n",
       " 'platform': 'Windows-11-10.0.26100-SP0',\n",
       " 'cpu_count': 16,\n",
       " 'timestamp': '2025-12-17T13:57:46.166614Z',\n",
       " 'drives': [{'drive': 'C:',\n",
       "   'total': 196172836864,\n",
       "   'used': 195559796736,\n",
       "   'free': 613040128},\n",
       "  {'drive': 'D:',\n",
       "   'total': 314571747328,\n",
       "   'used': 309730840576,\n",
       "   'free': 4840906752}],\n",
       " 'gpu': {'available': False, 'devices': []}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment discovery and checks\n",
    "import platform, multiprocessing, shutil, stat, math\n",
    "from datetime import datetime\n",
    "\n",
    "env = {}\n",
    "env['python_executable'] = sys.executable\n",
    "# pip version\n",
    "try:\n",
    "    pip_v = subprocess.check_output([sys.executable, '-m', 'pip', '--version'], text=True).strip()\n",
    "except Exception as e:\n",
    "    pip_v = str(e)\n",
    "env['pip_version'] = pip_v\n",
    "env['platform'] = platform.platform()\n",
    "env['cpu_count'] = multiprocessing.cpu_count()\n",
    "env['timestamp'] = datetime.utcnow().isoformat() + 'Z'\n",
    "\n",
    "# Disk usage for common drives (Windows-friendly)\n",
    "drives = []\n",
    "for d in ['C:', 'D:', 'E:', 'F:']:\n",
    "    if os.path.exists(d + os.sep):\n",
    "        try:\n",
    "            total, used, free = shutil.disk_usage(d + os.sep)\n",
    "            drives.append({'drive': d, 'total': total, 'used': used, 'free': free})\n",
    "        except Exception as e:\n",
    "            drives.append({'drive': d, 'error': str(e)})\n",
    "env['drives'] = drives\n",
    "\n",
    "# GPU check via torch (if installed)\n",
    "gpu_info = {'available': False, 'devices': []}\n",
    "try:\n",
    "    import importlib\n",
    "    torch_spec = importlib.util.find_spec('torch')\n",
    "    if torch_spec is not None:\n",
    "        import torch\n",
    "        gpu_info['available'] = torch.cuda.is_available()\n",
    "        if gpu_info['available']:\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                gpu_info['devices'].append({'id': i, 'name': torch.cuda.get_device_name(i)})\n",
    "except Exception as e:\n",
    "    gpu_info['error'] = str(e)\n",
    "env['gpu'] = gpu_info\n",
    "\n",
    "# Save env artifact\n",
    "write_artifact('env.json', env)\n",
    "env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c49464",
   "metadata": {},
   "source": [
    "### 5. Critical-library import/version check\n",
    "\n",
    "This cell probes for presence and versions of critical libraries used in the project. Results are saved to `artifacts/versions.json`. Missing libraries are marked clearly so reviewers know which packages to install.\n",
    "\n",
    "Why: Machine learning and LLM stacks are sensitive to package versions (ABI changes, tokenizer behavior, randomness). Capturing exact versions helps reproduce numeric results and model behavior. If a package is missing, the artifact makes it explicit which installation step failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2dc2e04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T13:57:48.148934Z",
     "iopub.status.busy": "2025-12-17T13:57:48.148660Z",
     "iopub.status.idle": "2025-12-17T13:57:54.355887Z",
     "shell.execute_reply": "2025-12-17T13:57:54.354273Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\rhyl-envs\\eclat_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote artifacts\\versions.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'openai': {'found': True, 'version': '2.13.0'},\n",
       " 'sentence_transformers': {'found': True, 'version': '5.2.0'},\n",
       " 'transformers': {'found': True, 'version': '4.57.3'},\n",
       " 'sklearn': {'found': True, 'version': '1.8.0'},\n",
       " 'xgboost': {'found': True, 'version': '3.1.2'},\n",
       " 'torch': {'found': True, 'version': '2.9.1+cpu'},\n",
       " 'networkx': {'found': True, 'version': '3.6.1'},\n",
       " 'pandas': {'found': True, 'version': '2.3.3'},\n",
       " 'jinja2': {'found': True, 'version': '3.1.6'},\n",
       " 'matplotlib': {'found': True, 'version': '3.10.8'},\n",
       " 'faiss': {'found': False, 'version': None},\n",
       " 'hnswlib': {'found': False, 'version': None}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Critical library presence and versions\n",
    "libraries = ['openai','sentence_transformers','transformers','sklearn','xgboost','torch','networkx','pandas','jinja2','matplotlib','faiss','hnswlib']\n",
    "import importlib, pkgutil\n",
    "present = {}\n",
    "for lib in libraries:\n",
    "    info = {'found': False, 'version': None}\n",
    "    try:\n",
    "        spec = importlib.util.find_spec(lib)\n",
    "        if spec is not None:\n",
    "            mod = importlib.import_module(lib)\n",
    "            info['found'] = True\n",
    "            info['version'] = getattr(mod, '__version__', None) or getattr(mod, 'VERSION', None)\n",
    "    except Exception as e:\n",
    "        info['error'] = str(e)\n",
    "    present[lib] = info\n",
    "\n",
    "write_artifact('versions.json', present)\n",
    "present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1584ce0e",
   "metadata": {},
   "source": [
    "### 6. Reproducibility manifest\n",
    "\n",
    "Compute and write a minimal manifest capturing `SEED`, current git commit (if available), SHA256 of `requirements.txt` (if present), platform, python path, and timestamp. Store the manifest in `artifacts/manifest.json`. This manifest should be included with any submission or experiment archive.\n",
    "\n",
    "Why: a manifest links the code that produced the results to the runtime snapshot. It helps answer questions like 'which commit produced these metrics?' and 'which requirements produced this behavior?'. For reviewers, the manifest is the minimal metadata bundle needed for re-running experiments or auditing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8772b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T13:57:54.358784Z",
     "iopub.status.busy": "2025-12-17T13:57:54.358322Z",
     "iopub.status.idle": "2025-12-17T13:57:54.412101Z",
     "shell.execute_reply": "2025-12-17T13:57:54.410593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote artifacts\\manifest.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'timestamp': '2025-12-17T13:57:54Z',\n",
       " 'platform': 'win32',\n",
       " 'python_executable': 'D:\\\\rhyl-envs\\\\eclat_venv\\\\Scripts\\\\python.exe',\n",
       " 'git_commit': None,\n",
       " 'requirements_sha256': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reproducibility manifest creation\n",
    "manifest = {'seed': SEED, 'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()), 'platform': sys.platform, 'python_executable': sys.executable}\n",
    "# git commit (if available)\n",
    "try:\n",
    "    git_hash = subprocess.check_output(['git','rev-parse','HEAD'], text=True).strip()\n",
    "    manifest['git_commit'] = git_hash\n",
    "except Exception:\n",
    "    manifest['git_commit'] = None\n",
    "# requirements.txt sha256 if present\n",
    "req_path = ROOT.joinpath('requirements.txt')\n",
    "if req_path.exists():\n",
    "    h = hashlib.sha256(req_path.read_bytes()).hexdigest()\n",
    "    manifest['requirements_sha256'] = h\n",
    "else:\n",
    "    manifest['requirements_sha256'] = None\n",
    "\n",
    "write_artifact('manifest.json', manifest)\n",
    "manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f7e06",
   "metadata": {},
   "source": [
    "### 7. Environment reproducibility guidance\n",
    "\n",
    "Follow these steps to reproduce the environment on Windows using the provided virtual environment or using Conda. Copy the commands into your terminal.\n",
    "\n",
    "**Windows venv (powershell)**\n",
    "\n",
    "```powershell\n",
    "python -m venv D:\\rhyl-envs\\eclat_venv\n",
    "D:\\rhyl-envs\\eclat_venv\\Scripts\\Activate.ps1\n",
    "pip install -U pip wheel\n",
    "pip install -r requirements.txt\n",
    "# optional: install plotting libs\n",
    "pip install matplotlib seaborn\n",
    "```\n",
    "\n",
    "**Conda (optional)**\n",
    "\n",
    "```bash\n",
    "conda create -n eclat python=3.10 -y\n",
    "conda activate eclat\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**Notes and rationale:** Prefer creating the venv on a drive with sufficient free space (see the env check above). Installing plotting libraries is optional for headless servers, but useful for visual inspection during reproducibility checks. If you are re-running experiments for numeric comparability, ensure that `requirements.txt` is the same file used to produce the original `requirements_sha256` recorded in the manifest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e956df6e",
   "metadata": {},
   "source": [
    "### 8. Notebook map\n",
    "\n",
    "One-line purposes for the remaining notebooks in the suite:\n",
    "\n",
    "- `notebooks/02_Data_Preparation.ipynb`: deterministic pipelines and feature engineering.\n",
    "- `notebooks/03_Baseline_Models.ipynb`: baseline classifiers and evaluation metrics.\n",
    "- `notebooks/04_Explainability.ipynb`: SHAP and surrogate model analyses.\n",
    "- `notebooks/05_LLM_Intent_Emotion.ipynb`: LLM wrapper experiments for intent and emotion detection.\n",
    "- `notebooks/06_Agents_Orchestration.ipynb`: MasterAgent and worker agent designs and small demos.\n",
    "- `notebooks/07_Verification_Workflows.ipynb`: KYC and verification pipelines.\n",
    "- `notebooks/08_Underwriting_Prefect.ipynb`: Prefect flows and policy simulations.\n",
    "- `notebooks/09_Sanction_Generator.ipynb`: jinja2 templates, audit trails, and signed artifacts.\n",
    "- `notebooks/10_Experiments_and_Results.ipynb`: experiment records, metrics tables, and plots for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe4dfb",
   "metadata": {},
   "source": [
    "### 9. Mathematical appendix (KaTeX) and References\n",
    "\n",
    "This appendix collects the core mathematical objects used across notebooks with brief pointers to classical references so reviewers can follow the theoretical basis used in modeling and evaluation.\n",
    "\n",
    "**a. Expected Loss (credit-risk)**:\n",
    "\n",
    "$EL = PD \\times LGD \\times EAD$\n",
    "\n",
    "(See: Basel Committee on Banking Supervision conceptual guidance on credit risk.)\n",
    "\n",
    "**b. Logistic regression (likelihood)**: for labels $y \\in \\{0,1\\}$ and features $x$, param $\\beta$,\n",
    "\n",
    "$$p(x) = \\sigma(x^T \\beta) = \\frac{1}{1 + e^{-x^T \\beta}}$$\n",
    "\n",
    "Negative log-likelihood with L2 regularization ($\\lambda$):\n",
    "\n",
    "$$L(\\beta) = -\\sum_i [y_i \\log p(x_i) + (1-y_i) \\log(1-p(x_i))] + \\frac{\\lambda}{2} ||\\beta||^2$$\n",
    "\n",
    "(See: Hosmer, Lemeshow & Sturdivant, Applied Logistic Regression.)\n",
    "\n",
    "**c. Brier score**: $BS = \\frac{1}{N} \\sum_{i=1}^N (p_i - y_i)^2$\n",
    "\n",
    "(Commonly used for probabilistic forecasts; see Brier (1950).)\n",
    "\n",
    "**d. POMDP formalism (MasterAgent)**: state $s$, action $a$, transition $T(s'|s,a)$, observation $o$, belief $b(s)$ with Bayesian update:\n",
    "\n",
    "$$b'(s') \\propto O(o|s',a) \\sum_s T(s'|s,a) b(s)$$\n",
    "\n",
    "(See: Puterman, Markov Decision Processes; Kaelbling et al. for POMDP overview.)\n",
    "\n",
    "**e. Pause-detection (exponential smoothing)**: given inter-utterance intervals $t_k$,\n",
    "\n",
    "$$\\hat{t}_k = \\alpha t_k + (1-\\alpha) \\hat{t}_{k-1}$$\n",
    "\n",
    "Pause rule: trigger if $t_k > \\mu + c \\cdot \\sigma$ for chosen constants $c$.\n",
    "\n",
    "**References (select):**\n",
    "\n",
    "- Brier, G. W. (1950). Verification of forecasts expressed in terms of probability. Monthly Weather Review.\n",
    "- Hosmer, D. W., Lemeshow, S., & Sturdivant, R. X. Applied Logistic Regression.\n",
    "- Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming.\n",
    "- Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning and acting in partially observable stochastic domains. Artificial Intelligence.\n",
    "- Basel Committee on Banking Supervision. (consultative papers on credit risk fundamentals)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
