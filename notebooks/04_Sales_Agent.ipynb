{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc7229d6",
   "metadata": {},
   "source": [
    "## Notebook 04: Sales Agent\n",
    "markdown\n",
    "markdown\n",
    "## Model Integration, Narrative Resonance & Fairness (prototype)\n",
    "\n",
    "- Goal: show a small, auditable prototype that approximates narrative resonance and urgency without requiring an LLM.\n",
    "- Approach: use a lightweight linear surrogate so feature attributions are exact (weight * feature), which serves as a SHAP-like explanation for this prototype.\n",
    "- Fairness rule: apply a penalty to urgency when credit score is below a threshold; the penalty scales with the urgency contribution so the effect is interpretable.\n",
    "- Note: this cell does not load any LoRA or Llama model. It demonstrates the integration points and the explanation+penalty pipeline in a reproducible way.\n",
    "code\n",
    "python\n",
    "# Prototype linear 'NarrativeModel' with exact feature contributions\n",
    "from dataclasses import dataclass\n",
    "def text_features(text):\n",
    "    t = text.lower()\n",
    "    return {\n",
    "        'story_future': 1.0 if 'future' in t or 'plan' in t or 'start' in t or 'next' in t else 0.0,\n",
    "        'urgency': 1.0 if 'urgent' in t or 'soon' in t or 'priority' in t else 0.0,\n",
    "        'emotional_valence': 1.0 if 'excited' in t or 'love' in t or 'great' in t else 0.0,\n",
    "    }\n",
    "@dataclass\n",
    "class NarrativeModel:\n",
    "    # weights for a linear surrogate; resonance and urgency share features but have separate weights\n",
    "    w_resonance: dict = None,\n",
    "    def __post_init__(self):\n",
    "        if self.w_resonance is None:\n",
    "            self.w_resonance = {'story_future': 0.6, 'urgency': 0.1, 'emotional_valence': 0.3}\n",
    "        if self.w_urgency is None:\n",
    "            self.w_urgency = {'story_future': 0.0, 'urgency': 0.8, 'emotional_valence': 0.2}\n",
    "    def predict(self, text):\n",
    "        f = text_features(text)\n",
    "        contrib_res = {k: self.w_resonance[k]*f[k] for k in f}\n",
    "        contrib_urg = {k: self.w_urgency[k]*f[k] for k in f}\n",
    "        resonance = sum(contrib_res.values())\n",
    "        urgency = sum(contrib_urg.values())\n",
    "        return {'resonance': resonance, 'urgency': urgency, 'contrib_res': contrib_res, 'contrib_urg': contrib_urg}\n",
    "# small demo\n",
    "model = NarrativeModel()\n",
    "examples = [ 'I plan to start next month and am excited about the future', 'This is urgent, we need priority support', 'Curious about pricing, not urgent' ]\n",
    "for ex in examples:\n",
    "    out = model.predict(ex)\n",
    "markdown\n",
    "#VSC-45de753f\n",
    "markdown\n",
    "## Notebook 04 — Sales Agent\n",
    "\n",
    "Brief: a compact, auditable reference implementation of a sales assistant pipeline. It demonstrates deterministic scoring, persona templates, finite-state conversation flows, offer generation, analytics, and a small, transparent prototype for narrative resonance and fairness (surrogate model).\n",
    "\n",
    "- **Purpose:** surface qualified opportunities reliably, audibly, and reproducibly.\n",
    "- **Design principles:** deterministic transforms; interpretability (explicit arithmetic); auditability (append-only events); reproducibility (same inputs → same outputs).\n",
    "- **Prototype note:** the narrative resonance model is a linear surrogate with exact per-feature attributions (weight × feature). This enables a SHAP-like explanation and a simple fairness penalty that reduces urgency when credit < threshold.\n",
    "\n",
    "Outputs: runnable examples, visualizations, and JSON artifacts written to the `artifacts/` folder.\n",
    "code\n",
    "#VSC-3e7e7b85\n",
    "python\n",
    "# Persona example: simple template mapping\n",
    "markdown\n",
    "## Notebook 04 — Sales Agent\n",
    "\n",
    "Brief: a compact, auditable reference implementation of a sales assistant pipeline. It demonstrates deterministic scoring, persona templates, finite-state conversation flows, offer generation, analytics, and a small, transparent prototype for narrative resonance and fairness (surrogate model).\n",
    "\n",
    "- **Purpose:** surface qualified opportunities reliably, audibly, and reproducibly.\n",
    "- **Design principles:** deterministic transforms; interpretability (explicit arithmetic); auditability (append-only events); reproducibility (same inputs → same outputs).\n",
    "- **Prototype note:** the narrative resonance model is a linear surrogate with exact per-feature attributions (weight × feature). This enables a SHAP-like explanation and a simple fairness penalty that reduces urgency when credit &lt; threshold.\n",
    "\n",
    "Outputs: runnable examples, visualizations, and JSON artifacts written to the `artifacts/` folder.\n",
    "code\n",
    "# Setup: imports and artifacts directory\n",
    "import json, math, random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "ARTIFACTS = Path('artifacts')\n",
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "print('Environment ready. Artifacts dir:', ARTIFACTS)\n",
    "print('matplotlib backend:', plt.get_backend())\n",
    "\n",
    "markdown\n",
    "## Persona — Tone, Claims, Fallbacks\n",
    "\n",
    "Purpose: keep responses consistent, safe, and testable.\n",
    "\n",
    "- **Styles:** `informative`, `consultative`, `escalate`.\n",
    "- **Mapping:** deterministic feature → score → argmax selects style.\n",
    "- **Templates:** small, reviewable strings; escalate when confidence is low.\n",
    "\n",
    "Example: the persona is a tiny policy object (enum + templates) that is exhaustively testable.\n",
    "code\n",
    "# Persona example: simple template mapping\n",
    "from dataclasses import dataclass, asdict\n",
    "@dataclass\n",
    "class Persona:\n",
    "    name: str\n",
    "    tone: str\n",
    "    templates: dict\n",
    "p = Persona(name='SalesPro', tone='consultative', templates={'greet': 'Hi {name}, thanks for reaching out.', 'followup': 'Are you available for a short call this week?'})\n",
    "print('Persona preview:')\n",
    "print(asdict(p))\n",
    "# render a template\n",
    "print('\n",
    "\n",
    "markdown\n",
    "## Core Conversation Flows\n",
    "\n",
    "Purpose: control dialog progression with small, verifiable state machines.\n",
    "\n",
    "- **Representation:** directed graph where nodes are states and edges have predicate guards.\n",
    "- **Guarantees:** analyze reachability and liveness; choose transitions by threshold or argmax when using scores.\n",
    "- **Benefit:** explicit flows prevent unexpected statements and simplify testing.\n",
    "\n",
    "Below: a minimal flow visualization and runnable FSM example.\n",
    "code\n",
    "# Simple FSM flow and visualization\n",
    "G = nx.DiGraph()\n",
    "states = ['start','qualify','proposal','handoff','closed']\n",
    "G.add_nodes_from(states)\n",
    "G.add_edge('start','qualify')\n",
    "G.add_edge('qualify','proposal')\n",
    "G.add_edge('proposal','closed')\n",
    "G.add_edge('proposal','handoff')\n",
    "pos = nx.spring_layout(G, seed=2)\n",
    "plt.figure(figsize=(6,4))\n",
    "nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=1200, arrowsize=20)\n",
    "plt.title('Conversation Flow (simple)')\n",
    "plt.show()\n",
    "print('Flow nodes:', list(G.nodes()))\n",
    "\n",
    "markdown\n",
    "## Lead Qualification — Deterministic Scoring\n",
    "\n",
    "Purpose: convert text + metadata into a compact numeric score for gating and prioritization.\n",
    "\n",
    "- **Features:** budget, timeline, decision-maker signals.\n",
    "- **Model:** interpretable linear scoring:\n",
    "\n",
    "$$score = w_1 x_1 + w_2 x_2 + \\dots + w_n x_n$$\n",
    "\n",
    "- Notes: weights are small and explainable; apply a sigmoid to convert to probability if needed.\n",
    "\n",
    "Below: a deterministic scorer, example outputs, and a simple visualization.\n",
    "code\n",
    "# Simple deterministic lead scorer\n",
    "def extract_features(text):\n",
    "    t = text.lower()\n",
    "    return {\n",
    "        'budget': 1 if 'budget' in t or '$' in t else 0,\n",
    "        'timeline': 1 if 'soon' in t or 'next' in t or 'month' in t else 0,\n",
    "        'decision_maker': 1 if 'i am' in t or 'we are' in t else 0\n",
    "    }\n",
    "def score_lead(text, weights=(0.5,0.3,0.2)):\n",
    "    f = extract_features(text)\n",
    "    vals = [f['budget'], f['timeline'], f['decision_maker']]\n",
    "    s = sum(w*v for w,v in zip(weights, vals))\n",
    "    return s, f\n",
    "examples = [ 'We have a $5000 budget and want to start next month', 'Curious about pricing', 'I am the manager and want a demo soon' ]\n",
    "scores = [score_lead(t) for t in examples]\n",
    "print('Lead scores and features:')\n",
    "for t,(s,f) in zip(examples,scores):\n",
    "    print('\n",
    "    print('SCORE:', s, 'FEATURES:', f)\n",
    "# plot bar chart\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.bar(range(len(scores)), [s for s,_ in scores], tick_label=[ 'ex1','ex2','ex3' ])\n",
    "plt.title('Lead Scores')\n",
    "plt.ylim(0,1.1)\n",
    "plt.show()\n",
    "\n",
    "markdown\n",
    "## Objection Handling\n",
    "\n",
    "Purpose: map common objections to short, safe rebuttals.\n",
    "\n",
    "- **Taxonomy:** class label → canonical response template.\n",
    "- **Escalation:** offer human handoff when confidence is low or request is out-of-scope.\n",
    "- **Safety:** keep responses concise and verifiable.\n",
    "\n",
    "Below: a small mapping and examples.\n",
    "code\n",
    "# Objection mapping demo\n",
    "objections = {\n",
    "    'price': 'I understand pricing is important. Can I show value relevant to your goals?',\n",
    "    'timing': 'I hear timing is tight. Would a short trial or phased roll-out help?',\n",
    "    'needs': 'Thanks for sharing that. Can you tell me which features matter most?'\n",
    "}\n",
    "sample = ['price','needs','other']\n",
    "for s in sample:\n",
    "    resp = objections.get(s, 'I will connect you with a specialist for that request.')\n",
    "    print(f'Objection: {s} -> Response: {resp}')\n",
    "\n",
    "markdown\n",
    "## Offer Generation and Pricing\n",
    "\n",
    "Purpose: produce deterministic, auditable quotes from structured inputs.\n",
    "\n",
    "- **Inputs:** quantity `q`, unit price `p`, discount `d`.\n",
    "- **Formula:** $$total = q \\cdot p \\cdot (1 - d)$$\n",
    "- **Design:** expose every intermediate value (subtotal, discount) for auditing.\n",
    "\n",
    "Below: example quote computation and breakdown visualization.\n",
    "code\n",
    "# Offer generation demo\n",
    "def quote(q, p, d=0.0):\n",
    "    subtotal = q*p\n",
    "    discount = subtotal * d\n",
    "    total = subtotal - discount\n",
    "    return {'qty':q,'unit':p,'subtotal':subtotal,'discount':discount,'total':total}\n",
    "q = 10; p = 199.0; d = 0.1\n",
    "qout = quote(q,p,d)\n",
    "print('Quote preview:', qout)\n",
    "# visualize breakdown\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.bar(['subtotal','discount','total'], [qout['subtotal'], qout['discount'], qout['total']], color=['#4c78a8','#f58518','#54a24b'])\n",
    "plt.title('Quote Breakdown')\n",
    "plt.show()\n",
    "\n",
    "markdown\n",
    "## Analytics, Signals, and Metrics\n",
    "\n",
    "Purpose: monitor agent health and conversion performance.\n",
    "\n",
    "- **Key metrics:** conversion rate, time-to-qualify, abandonment rate.\n",
    "- **Instrumentation:** record events (message, qualified, handoff) in append-only timelines (see Notebook 03).\n",
    "- **Use:** deterministic replays to compute metrics and compare rule changes.\n",
    "\n",
    "Below: a small event simulation and summary chart.\n",
    "code\n",
    "# Simulate events and compute simple metrics\n",
    "events = [ {'lead_id':1,'event':'message'},{'lead_id':1,'event':'qualified'},{'lead_id':1,'event':'closed'}, {'lead_id':2,'event':'message'},{'lead_id':2,'event':'abandoned'} ]\n",
    "total = len({e['lead_id'] for e in events})\n",
    "closed = len([e for e in events if e['event']=='closed'])\n",
    "abandoned = len([e for e in events if e['event']=='abandoned'])\n",
    "conv = closed/total\n",
    "print(f'Total leads: {total}, closed: {closed}, abandoned: {abandoned}, conversion rate: {conv:.2f}')\n",
    "plt.figure(figsize=(4,2))\n",
    "plt.bar(['closed','abandoned'], [closed,abandoned], color=['#2ca02c','#d62728'])\n",
    "plt.title('Outcomes')\n",
    "plt.show()\n",
    "\n",
    "print('\\nPreview lead:')\n",
    "## Integrations and Runtime\n",
    "\n",
    "Purpose: connect internal events to external systems safely and reliably.\n",
    "markdown\n",
    "- **Adapters:** convert internal artifacts to CRM, calendar, or handoff messages.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "543.10pythonpython3pythonPython 3Checklist before deploy: observability, alerting, error budgets, and privacy/compliance review.- Harden integrations: idempotency, retries, observability, and alerting.- Build A/B evaluation harness and offline fairness audits.- Add human-in-the-loop review and approval flows.- Replace surrogate with calibrated ML models (if GPU/inference available).Recommended follow-ups:## Next Steps & Roadmapmarkdownprint('Wrote audit artifact ->', ARTIFACTS / 'narrative_audit.json')pprint.pprint(audit)import pprint    json.dump(audit,f,indent=2)with open(ARTIFACTS / 'narrative_audit.json','w',encoding='utf-8') as f:# write audit artifact and preview    audit.append(rec)    rec = {'text': text, 'credit': credit, 'resonance': round(out['resonance'],3), 'raw_urgency': round(out['urgency'],3), 'penalized_urgency': round(v['penalized_urgency'],3), 'reason': v['reason']}    v = apply_fairness_penalty(out, credit)    out = model.predict(text)for text, credit in cases:audit = []cases = [(examples[0], 700), (examples[1], 580), (examples[2], 620)]]    'Curious about pricing, not urgent'    'This is urgent, we need priority support',    'I plan to start next month and am excited about the future',examples = [model = NarrativeModel()# Demo and compact audit    return {'raw_urgency': raw_urgency, 'penalized_urgency': penalized, 'reason': f'penalized (credit {credit_score} < {c0})', 'contrib_urgency': contrib_urgency}    penalized = max(0.0, raw_urgency - lamb * contrib_urgency)        return {'raw_urgency': raw_urgency, 'penalized_urgency': raw_urgency, 'reason':'no penalty', 'contrib_urgency': contrib_urgency}    if credit_score >= c0:    contrib_urgency = sum(out['contrib_urg'].values())    raw_urgency = out['urgency']def apply_fairness_penalty(out, credit_score, c0=600, lamb=0.8):        return {'resonance': resonance, 'urgency': urgency, 'contrib_res': contrib_res, 'contrib_urg': contrib_urg}        urgency = sum(contrib_urg.values())        resonance = sum(contrib_res.values())        contrib_urg = {k: self.w_urgency.get(k,0.0)*f.get(k,0.0) for k in f}        contrib_res = {k: self.w_resonance.get(k,0.0)*f.get(k,0.0) for k in f}        f = text_features(text)    def predict(self, text):            self.w_urgency = {'story_future': 0.0, 'urgency': 0.8, 'emotional_valence': 0.2}        if self.w_urgency is None:            self.w_resonance = {'story_future': 0.6, 'urgency': 0.1, 'emotional_valence': 0.3}        if self.w_resonance is None:    def __post_init__(self):    w_urgency: dict = None    w_resonance: dict = Noneclass NarrativeModel:@dataclass    }        'emotional_valence': 1.0 if any(w in t for w in ('excited','love','great')) else 0.0,        'urgency': 1.0 if any(w in t for w in ('urgent','soon','priority')) else 0.0,        'story_future': 1.0 if any(w in t for w in ('future','plan','start','next')) else 0.0,    return {    t = text.lower()def text_features(text):from dataclasses import dataclass# Prototype linear 'NarrativeModel' with exact feature contributionscodeNotes: this is a CPU-friendly prototype suitable for unit tests and audits. If you have model access and GPU, we can replace the surrogate with a LoRA adapter on an LLM; ask and I will add the exact `transformers` + `peft` cells and a `requirements.txt`.$$\\text{penalized\\_urgency} = \\max\\bigl(0, u - \\lambda \\cdot I[credit < c_0] \\cdot contrib_{urgency}\\bigr)$$Formula (penalized urgency):- **Fairness rule:** if `credit < c0` apply a penalty to urgency proportional to the summed urgency contribution. This is auditable and tunable.- **Surrogate model:** linear weights; per-feature contribution is exact (weight × feature) so explanations are unambiguous.Purpose: provide a small, fully transparent surrogate that approximates two behaviors: `resonance` (how well a message fits the customer's narrative) and raw `urgency`.## Narrative Resonance (Prototype) & Fairnessmarkdownprint(json.dumps(lead,indent=2))print('\n",
    "Preview lead:')print('Wrote artifacts:', ARTIFACTS / 'lead_sample.json', ARTIFACTS / 'offer_sample.json')with open(ARTIFACTS / 'offer_sample.json','w',encoding='utf-8') as f: json.dump(offer,f,indent=2)with open(ARTIFACTS / 'lead_sample.json','w',encoding='utf-8') as f: json.dump(lead,f,indent=2)offer = {'id':1,'lead_id':1,'total':1791.0}lead = {'id':1,'name':'ACME','score':0.82}codeBelow: a sample lead and offer writer and a preview of the files written.- **Format:** make artifacts minimal, typed, and easy to validate.- **Store:** leads, offers, and audit records under `artifacts/`.Purpose: produce JSON artifacts that serve as contracts between components.## Artifacts & Schema Exportsmarkdownprint('Deterministic tests passed')assert score_lead('Just browsing')[0] < 0.5assert score_lead('We have a $1000 budget and can start next month')[0] > 0.5# Deterministic testscodeBelow: a few assertions that should pass deterministically.- **Value:** prevent regressions and document expected behavior.- **Tests:** small, fast, pure assertions with fixed inputs.Purpose: codify invariants and expectations for reviewers and CI.## Deterministic Tests & Worked Examplesmarkdownprint(json.dumps(payload, indent=2))print('CRM payload (preview):')payload = build_crm_payload(42,'ACME Corp',0.78)    return {'lead_id':lead_id,'name':name,'score':score}def build_crm_payload(lead_id, name, score):# Integration stub: CRM payload buildercodeBelow: a stub adapter that prints the CRM payload instead of sending it.- **Pattern:** keep core logic pure and testable; adapters should be thin I/O layers.- **Best practices:** idempotency, clear error semantics, and retries with backoff.\n",
    "Suggestions for follow-up work include adding calibrated ML models for scoring, human-in-the-loop workflows, richer A/B evaluation harnesses, privacy and compliance reviews, and production hardening of integrations. Create a checklist for observability, alerting, and error budgeting before deploying."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
