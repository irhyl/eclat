{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc7229d6",
   "metadata": {},
   "source": [
    "## Notebook 04: Sales Agent\n",
    "markdown\n",
    "markdown\n",
    "## Model Integration, Narrative Resonance & Fairness (prototype)\n",
    "\n",
    "- Goal: show a small, auditable prototype that approximates narrative resonance and urgency without requiring an LLM.\n",
    "- Approach: use a lightweight linear surrogate so feature attributions are exact (weight * feature), which serves as a SHAP-like explanation for this prototype.\n",
    "- Fairness rule: apply a penalty to urgency when credit score is below a threshold; the penalty scales with the urgency contribution so the effect is interpretable.\n",
    "- Note: this cell does not load any LoRA or Llama model. It demonstrates the integration points and the explanation+penalty pipeline in a reproducible way.\n",
    "code\n",
    "python\n",
    "# Prototype linear 'NarrativeModel' with exact feature contributions\n",
    "from dataclasses import dataclass\n",
    "def text_features(text):\n",
    "    t = text.lower()\n",
    "    return {\n",
    "        'story_future': 1.0 if 'future' in t or 'plan' in t or 'start' in t or 'next' in t else 0.0,\n",
    "        'urgency': 1.0 if 'urgent' in t or 'soon' in t or 'priority' in t else 0.0,\n",
    "        'emotional_valence': 1.0 if 'excited' in t or 'love' in t or 'great' in t else 0.0,\n",
    "    }\n",
    "@dataclass\n",
    "class NarrativeModel:\n",
    "    # weights for a linear surrogate; resonance and urgency share features but have separate weights\n",
    "    w_resonance: dict = None,\n",
    "    def __post_init__(self):\n",
    "        if self.w_resonance is None:\n",
    "            self.w_resonance = {'story_future': 0.6, 'urgency': 0.1, 'emotional_valence': 0.3}\n",
    "        if self.w_urgency is None:\n",
    "            self.w_urgency = {'story_future': 0.0, 'urgency': 0.8, 'emotional_valence': 0.2}\n",
    "    def predict(self, text):\n",
    "        f = text_features(text)\n",
    "        contrib_res = {k: self.w_resonance[k]*f[k] for k in f}\n",
    "        contrib_urg = {k: self.w_urgency[k]*f[k] for k in f}\n",
    "        resonance = sum(contrib_res.values())\n",
    "        urgency = sum(contrib_urg.values())\n",
    "        return {'resonance': resonance, 'urgency': urgency, 'contrib_res': contrib_res, 'contrib_urg': contrib_urg}\n",
    "# small demo\n",
    "model = NarrativeModel()\n",
    "examples = [ 'I plan to start next month and am excited about the future', 'This is urgent, we need priority support', 'Curious about pricing, not urgent' ]\n",
    "for ex in examples:\n",
    "    out = model.predict(ex)\n",
    "markdown\n",
    "#VSC-45de753f\n",
    "markdown\n",
    "## Notebook 04 — Sales Agent\n",
    "\n",
    "Brief: a compact, auditable reference implementation of a sales assistant pipeline. It demonstrates deterministic scoring, persona templates, finite-state conversation flows, offer generation, analytics, and a small, transparent prototype for narrative resonance and fairness (surrogate model).\n",
    "\n",
    "- **Purpose:** surface qualified opportunities reliably, audibly, and reproducibly.\n",
    "- **Design principles:** deterministic transforms; interpretability (explicit arithmetic); auditability (append-only events); reproducibility (same inputs → same outputs).\n",
    "- **Prototype note:** the narrative resonance model is a linear surrogate with exact per-feature attributions (weight × feature). This enables a SHAP-like explanation and a simple fairness penalty that reduces urgency when credit < threshold.\n",
    "\n",
    "Outputs: runnable examples, visualizations, and JSON artifacts written to the `artifacts/` folder.\n",
    "code\n",
    "#VSC-3e7e7b85\n",
    "python\n",
    "# Persona example: simple template mapping\n",
    "from dataclasses import dataclass, asdict\n",
    "@dataclass\n",
    "class Persona:\n",
    "    name: str\n",
    "    tone: str\n",
    "    templates: dict\n",
    "p = Persona(name='SalesPro', tone='consultative', templates={'greet': 'Hi {name}, thanks for reaching out.', 'followup': 'Are you available for a short call this week?'})\n",
    "print('Persona preview:')\n",
    "print(asdict(p))\n",
    "# render a template\n",
    "print('\\nRendered greeting ->', p.templates['greet'].format(name='Alex'))\n",
    "markdown\n",
    "#VSC-08ffa8be\n",
    "markdown\n",
    "## 3. Core Conversation Flows\n",
    "\n",
    "Flows are small deterministic state machines that govern dialog progression. Each flow is a directed graph of states with guard conditions on transitions. Why: explicit flows make it easy to reason about possible paths and ensure we do not produce unexpected statements. How: represent flows as a directed graph where nodes are states and edges have predicate functions. From a CS theory perspective this is a finite state machine and can be analyzed for reachability and liveness properties. From a math perspective, when probabilistic signals are present, we treat them as scores and select transitions by thresholding or argmax. Below we synthesize a tiny flow and visualize it.\n",
    "code\n",
    "#VSC-787d2076\n",
    "python\n",
    "# Simple FSM flow and visualization\n",
    "G = nx.DiGraph()\n",
    "states = ['start','qualify','proposal','handoff','closed']\n",
    "G.add_nodes_from(states)\n",
    "G.add_edge('start','qualify')\n",
    "G.add_edge('qualify','proposal')\n",
    "G.add_edge('proposal','closed')\n",
    "G.add_edge('proposal','handoff')\n",
    "pos = nx.spring_layout(G, seed=2)\n",
    "plt.figure(figsize=(6,4))\n",
    "nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=1200, arrowsize=20)\n",
    "plt.title('Conversation Flow (simple)')\n",
    "plt.show()\n",
    "print('Flow nodes:', list(G.nodes()))\n",
    "markdown\n",
    "#VSC-3cb46b81\n",
    "markdown\n",
    "## 4. Lead Qualification Logic\n",
    "\n",
    "Qualification converts raw text and metadata into a compact numeric score that summarizes how likely a lead is to convert. Why: a single score enables simple gating rules and prioritization. How: extract a few features such as explicit budget mention, timeline words, and decision maker indicators. Compute a weighted sum score:\n",
    "\n",
    "$$score = w_1 x_1 + w_2 x_2 + \\dots + w_n x_n$$\n",
    "\n",
    "We choose weights to be interpretable and small in number so that each weight's effect is clear. From a CS perspective this is a linear model; from a statistics perspective it is a logistic-like ranking if we apply a sigmoid to obtain a probability estimate. Below we implement a tiny deterministic scorer, run it on examples, and plot the resulting scores.\n",
    "code\n",
    "#VSC-0a55cc70\n",
    "python\n",
    "# Simple deterministic lead scorer\n",
    "def extract_features(text):\n",
    "    t = text.lower()\n",
    "    return {\n",
    "        'budget': 1 if 'budget' in t or '$' in t else 0,\n",
    "        'timeline': 1 if 'soon' in t or 'next' in t or 'month' in t else 0,\n",
    "        'decision_maker': 1 if 'i am' in t or 'we are' in t else 0\n",
    "    }\n",
    "def score_lead(text, weights=(0.5,0.3,0.2)):\n",
    "    f = extract_features(text)\n",
    "    vals = [f['budget'], f['timeline'], f['decision_maker']]\n",
    "    s = sum(w*v for w,v in zip(weights, vals))\n",
    "    return s, f\n",
    "examples = [ 'We have a $5000 budget and want to start next month', 'Curious about pricing', 'I am the manager and want a demo soon' ]\n",
    "scores = [score_lead(t) for t in examples]\n",
    "print('Lead scores and features:')\n",
    "for t,(s,f) in zip(examples,scores):\n",
    "    print('\\nTEXT:', t)\n",
    "    print('SCORE:', s, 'FEATURES:', f)\n",
    "# plot bar chart\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.bar(range(len(scores)), [s for s,_ in scores], tick_label=[ 'ex1','ex2','ex3' ])\n",
    "plt.title('Lead Scores')\n",
    "plt.ylim(0,1.1)\n",
    "plt.show()\n",
    "markdown\n",
    "#VSC-8c5ec35e\n",
    "markdown\n",
    "## 5. Objection Handling and Rebuttals\n",
    "\n",
    "Objection handling is a small rule set mapping common negative intents to safe, concise responses. Why: many sales conversations hinge on addressing a handful of objections well. How: encode an objection taxonomy and a canonical response template for each class. From an algorithmic perspective this is a deterministic mapping from a recognized objection label to a response. We keep templates short and require the agent to offer an option to escalate to a human when confidence is low. This keeps behavior safe and predictable. The code cell demonstrates a simple mapping and example lookups.\n",
    "code\n",
    "#VSC-d5daa7a4\n",
    "python\n",
    "# Objection mapping demo\n",
    "objections = {\n",
    "    'price': 'I understand pricing is important. Can I show value relevant to your goals?',\n",
    "    'timing': 'I hear timing is tight. Would a short trial or phased roll-out help?',\n",
    "    'needs': 'Thanks for sharing that. Can you tell me which features matter most?'\n",
    "markdown\n",
    "#VSC-50e21695\n",
    "markdown\n",
    "## Persona — Tone, Claims, Fallbacks\n",
    "\n",
    "Purpose: keep responses consistent, safe, and testable.\n",
    "\n",
    "- **Styles:** `informative`, `consultative`, `escalate`.\n",
    "- **Mapping:** deterministic feature → score → argmax selects style.\n",
    "- **Templates:** small, reviewable strings; escalate when confidence is low.\n",
    "\n",
    "Example: the persona is a tiny policy object (enum + templates) that is exhaustively testable.\n",
    "$$total = q \\cdot p \\cdot (1 - d)$$\n",
    "\n",
    "The code cell computes an example quote and visualizes the price breakdown.\n",
    "code\n",
    "#VSC-a7c72309\n",
    "python\n",
    "# Offer generation demo\n",
    "def quote(q, p, d=0.0):\n",
    "    subtotal = q*p\n",
    "    discount = subtotal * d\n",
    "    total = subtotal - discount\n",
    "    return {'qty':q,'unit':p,'subtotal':subtotal,'discount':discount,'total':total}\n",
    "q = 10; p = 199.0; d = 0.1\n",
    "qout = quote(q,p,d)\n",
    "print('Quote preview:', qout)\n",
    "# visualize breakdown\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.bar(['subtotal','discount','total'], [qout['subtotal'], qout['discount'], qout['total']], color=['#4c78a8','#f58518','#54a24b'])\n",
    "plt.title('Quote Breakdown')\n",
    "plt.show()\n",
    "markdown\n",
    "#VSC-acc20a3b\n",
    "markdown\n",
    "## 7. Analytics, Signals and Metrics\n",
    "\n",
    "Capture a small set of signals to monitor agent health and conversion. Why: metrics show whether rule changes improve outcomes. Key metrics include conversion rate, average time to qualified lead, and abandonment rate. How: instrument events for each message, qualification change, and handoff. With append-only timelines from Notebook 03 we can replay experiments deterministically and compute metrics on the recorded events. The code cell below simulates a small event stream, computes summary metrics, and draws a chart.\n",
    "code\n",
    "#VSC-e3f7b028\n",
    "python\n",
    "# Simulate events and compute simple metrics\n",
    "events = [ {'lead_id':1,'event':'message'},{'lead_id':1,'event':'qualified'},{'lead_id':1,'event':'closed'}, {'lead_id':2,'event':'message'},{'lead_id':2,'event':'abandoned'} ]\n",
    "total = len({e['lead_id'] for e in events})\n",
    "closed = len([e for e in events if e['event']=='closed'])\n",
    "abandoned = len([e for e in events if e['event']=='abandoned'])\n",
    "conv = closed/total\n",
    "print(f'Total leads: {total}, closed: {closed}, abandoned: {abandoned}, conversion rate: {conv:.2f}')\n",
    "plt.figure(figsize=(4,2))\n",
    "plt.bar(['closed','abandoned'], [closed,abandoned], color=['#2ca02c','#d62728'])\n",
    "plt.title('Outcomes')\n",
    "plt.show()\n",
    "markdown\n",
    "#VSC-a9c6b15b\n",
    "markdown\n",
    "## 8. Integrations and Runtime\n",
    "\n",
    "Sketch how the components connect to runtime and external systems. Why: integration rules ensure production reliability. How: define small adapters that convert internal events to CRM API calls, calendar invites, or human handoff messages. Emphasize idempotency, retries, and clear error semantics. From a CS perspective these adapters are thin I/O layers; the core logic remains pure and testable. The code cell below shows a stub adapter that prints the CRM payload rather than making a network call.\n",
    "code\n",
    "#VSC-2402b540\n",
    "python\n",
    "# Integration stub: CRM payload builder\n",
    "def build_crm_payload(lead_id, name, score):\n",
    "    return {'lead_id':lead_id,'name':name,'score':score}\n",
    "payload = build_crm_payload(42,'ACME Corp',0.78)\n",
    "print('CRM payload (preview):')\n",
    "print(json.dumps(payload, indent=2))\n",
    "markdown\n",
    "#VSC-fd7d6e8c\n",
    "markdown\n",
    "## 9. Deterministic Tests and Worked Examples\n",
    "\n",
    "Provide unit tests that assert core invariants, so reviewers can run them with confidence. Why: tests prevent regressions and document expected behavior. How: build small examples with fixed inputs and assert exact outputs. Keep tests fast and pure. The code cell below executes a few assertions and prints a short report.\n",
    "code\n",
    "#VSC-0d810d19\n",
    "python\n",
    "# Deterministic tests\n",
    "assert score_lead('We have a $1000 budget and can start next month')[0] > 0.5\n",
    "assert score_lead('Just browsing')[0] < 0.5\n",
    "print('Deterministic tests passed')\n",
    "markdown\n",
    "#VSC-bcb48065\n",
    "markdown\n",
    "## 10. Artifacts and Schema Exports\n",
    "\n",
    "Export simple JSON artifacts for leads and offers so downstream systems can validate inputs. Why: artifacts act as a contract between components. How: write small JSON files into the artifacts directory and preview them inline. The code cell writes a sample lead and offer and prints the file paths.\n",
    "code\n",
    "#VSC-3499f1d5\n",
    "python\n",
    "lead = {'id':1,'name':'ACME','score':0.82}\n",
    "offer = {'id':1,'lead_id':1,'total':1791.0}\n",
    "with open(ARTIFACTS / 'lead_sample.json','w',encoding='utf-8') as f: json.dump(lead,f,indent=2)\n",
    "with open(ARTIFACTS / 'offer_sample.json','w',encoding='utf-8') as f: json.dump(offer,f,indent=2)\n",
    "print('Wrote artifacts:', ARTIFACTS / 'lead_sample.json', ARTIFACTS / 'offer_sample.json')\n",
    "print('\\nPreview lead:')\n",
    "print(json.dumps(lead,indent=2))\n",
    "markdown\n",
    "#VSC-622d587a\n",
    "markdown\n",
    "## Next Steps and Roadmap\n",
    "\n",
    "Suggestions for follow-up work include adding calibrated ML models for scoring, human-in-the-loop workflows, richer A/B evaluation harnesses, privacy and compliance reviews, and production hardening of integrations. Create a checklist for observability, alerting, and error budgeting before deploying."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
