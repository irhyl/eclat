{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a8d522",
   "metadata": {},
   "source": [
    "# 01 â€” Problem Formulation (Detailed)\n",
    "\n",
    "This notebook provides a formal, mathematically grounded statement of the tasks the system must solve, the operational constraints, and the evaluation metrics. The goal is to make tradeoffs explicit and to derive metrics that drive model selection and policy thresholds.\n",
    "\n",
    "Problem statement\n",
    "\n",
    "Given a stream of inbound events $xim D$ (messages, metadata, signals), produce for each $x$ an action $an A$ and an artifact $z$ containing the score, explanation, and provenance. The system should maximize expected operational utility under safety and audit constraints.\n",
    "\n",
    "Mathematical objective\n",
    "\n",
    "Define utility $U(a,x)$ as expected reward minus cost. The production policy $i$ chooses $a$ to approximately maximize expected utility:\n",
    "\n",
    "$$i(x) pprox rgax_{an A} athbb{E}[R(a,X)id X=x] - C(a),$$\n",
    "\n",
    "where $R$ is a stochastic reward (e.g., conversion revenue) and $C$ is the operational cost of pursuing action $a$.\n",
    "\n",
    "Evaluation metrics\n",
    "\n",
    "- Precision@k: $athrm{P@k} = \frac{1}{k}um_{i=1}^k athbf{1}\text{item}_i\text{is true opportunity}$ for ranked lists.\n",
    "- Recall: fraction of opportunities recovered at a threshold.\n",
    "- Expected cost per positive: $E[Cid \text{pursue}]$.\n",
    "- Offline policy evaluation: use importance sampling or inverse propensity weighting to estimate counterfactual performance when comparing policies.\n",
    "\n",
    "Safety and audit constraints\n",
    "\n",
    "- Every automated `pursue` decision must include an artifact with the scored features and the exact arithmetic that generated the score.\n",
    "- Restrict automated actions to those with confidence above conservative thresholds; lower confidence actions should be flagged for human review.\n",
    "\n",
    "Experimental design notes\n",
    "\n",
    "- Use randomized rollouts and stratified sampling to measure causal impact on conversion.\n",
    "- Monitor calibration drift over time; recalibrate scores (via isotonic regression or Platt scaling) when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ea3b7",
   "metadata": {},
   "source": [
    "## Decision thresholds and calibration\n",
    "\n",
    "Calibration: if a model outputs an unbounded score $s(x)$, convert to probability with a link function $p=igma(s)$ or calibrate empirically: learn a monotone mapping $g$ such that $g(s)pprox P(\text{positive}id s)$.\n",
    "\n",
    "Threshold selection: choose threshold $\tau$ to maximize expected utility given estimated conversion probability $p(x)$ and cost $c$: pursue when $p(x)dot V - c > 0$, where $V$ is expected value of conversion. This directly ties business economics to the decision rule."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
