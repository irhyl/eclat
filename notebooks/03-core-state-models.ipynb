{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da2f5e0",
   "metadata": {},
   "source": [
    "## 04: Core State Models & Psychological Representation\n",
    "\n",
    "This notebook is designed to bridge the gap between conceptual descriptions of conversational behaviors and a small, executable codebase. The primary intent is to provide clear, typed data models, straightforward temporal primitives for recording event history, and a few interpretable update rules that capture common conversational phenomena such as abandonment, pauses, and readiness shifts. Each algorithm is intentionally small; the focus is on understandability, testability, and being able to reason about behavior deterministically.\n",
    "\n",
    "For reproducible downstream processing, we export canonical JSON schemas for the core Pydantic models. The artifact writer serializes the Pydantic `.schema()` output for `Message` and `UserContext` and writes them to `artifacts/state_schema.json`. This file can be used by other notebooks, data validation pipelines, or serializer/deserializer code in production. Making the schema an explicit artifact ensures that changes to models are visible and versionable.## Notebook 03: Core State Models & Psychological Representation\n",
    "\n",
    "This notebook provides compact, typed data models, temporal graph primitives for append-only event history, and a set of small, interpretable update rules (ABANDON increment, pause detection, readiness update) together with a lightweight runtime and deterministic tests. The goal is understandability, auditability, and reproducible behavior for downstream consumers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b1b64",
   "metadata": {},
   "source": [
    "### 1. Enums & Pydantic schemas\n",
    "\n",
    "This section defines compact enumerations and their Pydantic-hosted schemas so downstream systems can treat symbolic states as first-class, typed values. An enumeration corresponds to a categorical variable; if there are $n$ categories then any probability vector over those categories lies on the standard simplex:\n",
    "\n",
    "$$\\Delta^{n-1} = \\{\\pi \\in \\mathbb{R}^n_{\\ge 0} : \\sum_{i=1}^n \\pi_i = 1\\}$$\n",
    "\n",
    "Practically, we use enums to represent compact label sets such as emotional valence or intent clarity, and Pydantic to serialize, validate, and emit JSON Schema. For many downstream uses we expose both the symbolic enum and its one-hot or probability encoding: if $e_i$ is the one-hot for category $i$, then the mapping to probabilities is $\\pi = e_i$ for a deterministic label, or any convex combination for calibrated outputs. Using the schema artifact enables robust input validation and automated contract checks in pipelines. The JSON Schema also documents allowed values, types, and field descriptions so that clients can programmatically discover the contract and perform safe conversions between symbolic enums and numeric vectors.\n",
    "\n",
    "Enums give us a shared vocabulary between humans and code. The schema makes that vocabulary machine-readable so other programs can validate inputs and avoid subtle mapping bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767e4b6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T03:54:06.320870Z",
     "iopub.status.busy": "2025-12-18T03:54:06.320518Z",
     "iopub.status.idle": "2025-12-18T03:54:06.471609Z",
     "shell.execute_reply": "2025-12-18T03:54:06.470706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message OK: m1 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADITI\\AppData\\Local\\Temp\\ipykernel_9744\\2357771918.py:40: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  @validator('readiness')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from enum import Enum\n",
    "from typing import Optional, List, Dict, Any, Sequence\n",
    "from pydantic import BaseModel, Field, validator\n",
    "import json\n",
    "from pathlib import Path\n",
    "ARTIFACTS = Path('artifacts')\n",
    "ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class EmotionalState(str, Enum):\n",
    "    NEUTRAL = 'neutral'\n",
    "    POSITIVE = 'positive'\n",
    "    NEGATIVE = 'negative'\n",
    "    FRUSTRATED = 'frustrated'\n",
    "    ENGAGED = 'engaged'\n",
    "\n",
    "class IntentClarity(str, Enum):\n",
    "    CLEAR = 'clear'\n",
    "    AMBIGUOUS = 'ambiguous'\n",
    "    UNKNOWN = 'unknown'\n",
    "\n",
    "class Message(BaseModel):\n",
    "    id: str = Field(..., description='Unique message identifier')\n",
    "    sender: str\n",
    "    recipient: Optional[str]\n",
    "    text: str\n",
    "    ts: float = Field(..., description='Timestamp in seconds (monotonic/epoch)')\n",
    "    emotional_state: Optional[EmotionalState] = EmotionalState.NEUTRAL\n",
    "    intent_clarity: Optional[IntentClarity] = IntentClarity.UNKNOWN\n",
    "    metadata: Optional[Dict[str, Any]] = None\n",
    "\n",
    "class UserContext(BaseModel):\n",
    "    user_id: str\n",
    "    last_seen_ts: Optional[float] = None\n",
    "    readiness: Optional[List[float]] = Field(default_factory=lambda: [1.0], description='Normalized readiness distribution')\n",
    "    emotional_state: EmotionalState = EmotionalState.NEUTRAL\n",
    "    intent_clarity: IntentClarity = IntentClarity.UNKNOWN\n",
    "    notes: Optional[str] = None\n",
    "\n",
    "    @validator('readiness')\n",
    "    def normalize_readiness(cls, v):\n",
    "        if not v:\n",
    "            return [1.0]\n",
    "        s = sum(v)\n",
    "        if s <= 0:\n",
    "            raise ValueError('readiness must sum to > 0')\n",
    "        return [float(x) / s for x in v]\n",
    "\n",
    "# quick sanity\n",
    "m = Message(id='m1', sender='user1', recipient='bot', text='hello', ts=0.0)\n",
    "print('Message OK:', m.id, m.ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7ef62",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________\n",
    "### 2. Temporal graph primitives\n",
    "\n",
    "This section describes the append-only temporal graph representation used to record interactions as immutable event lists attached to directed edges. Formally, let $G=(V,E)$ be a directed graph and for each edge $(u,v)\\in E$ associate an event sequence $\\mathcal{E}_{uv} = \\{(t_i, w_i, m_i)\\}_{i=1}^T$, where $t_i$ is the timestamp, $w_i$ a scalar weight, and $m_i$ optional metadata. A basic read operation recovers the most recent weight strictly before time $t$:\n",
    "\n",
    "$$w_{uv}(t) = \\max\\{w_i : (t_i,w_i) \\in \\mathcal{E}_{uv},\\ t_i \\le t\\}\\,,\\quad\\text{(step-replay)}$$\n",
    "\n",
    "Alternative analyses use decay kernels $K(\\tau)$ to compute a continuous influence score:\n",
    "\n",
    "$$W_{uv}(t) = \\sum_{(t_i,w_i) \\in \\mathcal{E}_{uv}} w_i\\,K(t - t_i)\\,,$$\n",
    "\n",
    "with $K$ chosen to trade off recency and memory (for example $K(\\tau)=e^{-\\lambda\\tau}$). Append-only semantics guarantee auditability and deterministic replay: the raw event list is preserved so downstream experiments can re-evaluate $W_{uv}(t)$ under different kernels or aggregation rules without loss. Appends are constant-time and compact, and storage can be controlled by pruning or summarization offline while preserving the canonical timeline for reproducibility.\n",
    "\n",
    "We keep every event so that any later analysis or fix can be replayed deterministically. This makes debugging and experimenting with different aggregation rules safe and auditable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aeece9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T03:54:06.475114Z",
     "iopub.status.busy": "2025-12-18T03:54:06.474857Z",
     "iopub.status.idle": "2025-12-18T03:54:06.755511Z",
     "shell.execute_reply": "2025-12-18T03:54:06.754482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge weight at t=0.5 -> 0.1\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from typing import Any, Optional\n",
    "\n",
    "def make_temporal_graph() -> nx.DiGraph:\n",
    "    return nx.DiGraph()\n",
    "\n",
    "def add_event_edge(G: nx.DiGraph, src: str, dst: str, ts: float, weight: float = 0.0, **meta: Any):\n",
    "    if G.has_edge(src, dst):\n",
    "        if 'events' not in G[src][dst]:\n",
    "            G[src][dst]['events'] = []\n",
    "        G[src][dst]['events'].append({'ts': float(ts), 'weight': float(weight), **meta})\n",
    "    else:\n",
    "        G.add_edge(src, dst, events=[{'ts': float(ts), 'weight': float(weight), **meta}])\n",
    "\n",
    "def edge_weight_at(G: nx.DiGraph, src: str, dst: str, ts: Optional[float] = None) -> float:\n",
    "    if not G.has_edge(src, dst):\n",
    "        return 0.0\n",
    "    events = G[src][dst].get('events', [])\n",
    "    if not events:\n",
    "        return 0.0\n",
    "    if ts is None:\n",
    "        return float(events[-1]['weight'])\n",
    "    eligible = [e for e in events if e['ts'] <= ts]\n",
    "    if not eligible:\n",
    "        return 0.0\n",
    "    return float(sorted(eligible, key=lambda e: e['ts'])[-1]['weight'])\n",
    "\n",
    "# quick check\n",
    "G = make_temporal_graph()\n",
    "add_event_edge(G, 'u','v', ts=0.0, weight=0.1)\n",
    "add_event_edge(G, 'u','v', ts=1.0, weight=0.4)\n",
    "print('edge weight at t=0.5 ->', edge_weight_at(G,'u','v', ts=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f44e3d",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________\n",
    "### 3. ABANDON math + helper\n",
    "\n",
    "The ABANDON rule is a simple, interpretable incremental score that grows when the predicted reply probability is low. Represent the current abandon weight on an edge as $w_t\\in[0,1]$. Given a reply probability estimate $p\\in[0,1]$ and a learning rate $\\alpha\\in[0,1]$, the increment is:\n",
    "\n",
    "$$\\delta_t = \\alpha\\,\\left(1 - p\\right)\\,,$$\n",
    "\n",
    "and the updated weight before clipping is $w_t + \\delta_t$. To ensure the weight remains in the unit interval we apply clipping:\n",
    "\n",
    "$$w_{t+1} = \\operatorname{clip}(w_t + \\delta_t,\\ 0,\\ 1)\\,,$$\n",
    "\n",
    "where $\\operatorname{clip}(x,a,b)=\\min(b,\\max(a,x))$. The implementation appends an event $(t,w_{t+1},meta)$ to the edge's timeline rather than mutating aggregate state, preserving the full audit trail. This approach is deterministic given fixed inputs and timestamps, and it supports replay: by re-evaluating the same sequence of $(p,\\alpha,t)$ updates one recovers the same $w$ trajectory. \n",
    "\n",
    "The choice of $\\alpha$ controls sensitivity: small $\\alpha$ yields slow accumulation, large $\\alpha$ reacts quickly to single low-probability events. Recording the $(p,\\alpha)$ pair per event allows offline calibration and analysis of how ABANDON evolves under different models.\n",
    "\n",
    "In short, we slowly increase a small abandon score when replies look unlikely. This gives a simple, auditable signal that can drive followup actions or monitoring alerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef66233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T03:54:06.759255Z",
     "iopub.status.busy": "2025-12-18T03:54:06.758823Z",
     "iopub.status.idle": "2025-12-18T03:54:06.765954Z",
     "shell.execute_reply": "2025-12-18T03:54:06.765200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before 0.2\n",
      "wb,wa 0.2 0.4\n"
     ]
    }
   ],
   "source": [
    "def apply_abandon_increment(G, src: str, dst: str, alpha: float, p_reply: float, ts: float):\n",
    "    \"\"\"Apply ABANDON increment and append event. Returns (w_before, w_after).\"\"\"\n",
    "    w_before = edge_weight_at(G, src, dst, ts=ts)\n",
    "    delta = float(alpha) * (1.0 - float(p_reply))\n",
    "    w_after = min(1.0, max(0.0, w_before + delta))\n",
    "    add_event_edge(G, src, dst, ts=ts, weight=w_after, reason='abandon', alpha=alpha, p_reply=p_reply)\n",
    "    return w_before, w_after\n",
    "\n",
    "# demonstration\n",
    "G_demo = make_temporal_graph()\n",
    "add_event_edge(G_demo, 'user1','bot', ts=0.0, weight=0.2)\n",
    "print('before', edge_weight_at(G_demo,'user1','bot'))\n",
    "wb, wa = apply_abandon_increment(G_demo, 'user1','bot', alpha=0.5, p_reply=0.6, ts=1.0)\n",
    "print('wb,wa', wb, wa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fc18b8",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________\n",
    "### 4. Pause detection math + smoother class\n",
    "\n",
    "Detecting pauses robustly requires a lightweight online statistic that adapts to recent conversation tempo while remaining resistant to transient spikes. \n",
    "\n",
    "The exponential smoother implemented in this notebook maintains two compact statistics: a running mean and a running second moment. From these we compute variance as $\\mathbb{E}[x^2] - (\\mathbb{E}[x])^2$, which is numerically stable for streaming updates. \n",
    "\n",
    "The smoother uses a single hyperparameter $\\alpha$ (smoothing factor) that governs the trade-off between responsiveness and stability - larger $\\alpha$ means the smoother reacts faster to new intervals, smaller $\\alpha$ makes it more conservative.\n",
    "\n",
    "The pause test itself is intentionally simple and interpretable: given the latest inter-message interval $\\Delta t$, compute the z-like score $z = (\\Delta t - \\mu)/\\sigma$ where $\\mu$ and $\\sigma$ are the smoother mean and standard deviation. If $z$ exceeds a threshold $k$, we flag a pause. This leverages empirical variability rather than absolute thresholds, so the detector adapts to different users and contexts without changing parameters.\n",
    "\n",
    "We detect unusually long pauses relative to the recent tempo so the system can trigger reminders, followups, or logging for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44025be3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T03:54:06.769367Z",
     "iopub.status.busy": "2025-12-18T03:54:06.768799Z",
     "iopub.status.idle": "2025-12-18T03:54:06.778548Z",
     "shell.execute_reply": "2025-12-18T03:54:06.777439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update 0.5 -> (0.5, 0.0)\n",
      "update 0.6 -> (0.52, 0.039999999999999876)\n",
      "update 0.55 -> (0.526, 0.03773592452822616)\n",
      "update 0.45 -> (0.5108, 0.04542422261305039)\n",
      "mean,std after small deltas 0.5108 0.04542422261305039\n",
      "detect pause with 10.0 -> True\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "@dataclass\n",
    "class ExpSmoother:\n",
    "    alpha: float = 0.2\n",
    "    mean: float = 0.0\n",
    "    second_moment: float = 0.0\n",
    "    initialized: bool = False\n",
    "\n",
    "    def update(self, x: float):\n",
    "        x = float(x)\n",
    "        if not self.initialized:\n",
    "            self.mean = x\n",
    "            self.second_moment = x * x\n",
    "            self.initialized = True\n",
    "            return self.mean, self.std\n",
    "        self.mean = self.alpha * x + (1 - self.alpha) * self.mean\n",
    "        self.second_moment = self.alpha * (x * x) + (1 - self.alpha) * self.second_moment\n",
    "        return self.mean, self.std\n",
    "\n",
    "    @property\n",
    "    def var(self) -> float:\n",
    "        v = self.second_moment - (self.mean * self.mean)\n",
    "        return max(0.0, v)\n",
    "\n",
    "    @property\n",
    "    def std(self) -> float:\n",
    "        return math.sqrt(self.var)\n",
    "\n",
    "def detect_pause(delta_t: float, smoother: ExpSmoother, k: float = 2.0) -> bool:\n",
    "    if not smoother.initialized:\n",
    "        return False\n",
    "    return float(delta_t) > (smoother.mean + float(k) * smoother.std)\n",
    "\n",
    "# small diagnostics\n",
    "s = ExpSmoother(alpha=0.2)\n",
    "for d in [0.5,0.6,0.55,0.45]:\n",
    "    print('update', d, '->', s.update(d))\n",
    "print('mean,std after small deltas', s.mean, s.std)\n",
    "print('detect pause with 10.0 ->', detect_pause(10.0, s, k=2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7015e",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________\n",
    "### 5. Readiness update math + function\n",
    "\n",
    "Readiness is a compact, probabilistic summary of how prepared an agent or user is to take some next action. We represent readiness as a probability vector π over discrete outcomes and update it on each observation using a multiplicative, discounted rule. \n",
    "\n",
    "The update multiplies a discounted prior (π_t ** γ) by the evidence likelihood for each outcome, then re-normalizes to remain on the probability simplex. This form behaves like a tempered Bayesian update: discounting via `γ` implements inertia so that short, noisy signals do not cause large swings, while the multiplicative factor ensures evidence is weighted proportionally to prior belief.\n",
    "\n",
    "Numerical safeguards are important: clamp tiny values with a small epsilon before exponentiation or multiplication to avoid underflow or zeroing out the distribution. \n",
    "\n",
    "If the normalizer sum becomes zero due to numerical issues, fall back to a uniform distribution to preserve validity. The update is intentionally model-agnostic: the likelihood input can come from a classifier, a heuristic, or a learned model, so long as it represents relative support for outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc0b66b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T03:54:06.781852Z",
     "iopub.status.busy": "2025-12-18T03:54:06.781593Z",
     "iopub.status.idle": "2025-12-18T03:54:06.788623Z",
     "shell.execute_reply": "2025-12-18T03:54:06.787583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update_readiness -> [0.25694227692548016, 0.74305772307452]\n"
     ]
    }
   ],
   "source": [
    "def update_readiness(pi_t: Sequence[float], likelihood: Sequence[float], gamma: float = 0.9) -> List[float]:\n",
    "    if len(pi_t) != len(likelihood):\n",
    "        raise ValueError('pi_t and likelihood must have same length')\n",
    "    eps = 1e-12\n",
    "    updated = [(max(eps, p) ** gamma) * max(eps, l) for p, l in zip(pi_t, likelihood)]\n",
    "    s = sum(updated)\n",
    "    if s <= 0:\n",
    "        n = len(updated)\n",
    "        return [1.0 / n] * n\n",
    "    return [float(u) / s for u in updated]\n",
    "\n",
    "# demo: prior favors first state but likelihood favors second\n",
    "print('update_readiness ->', update_readiness([0.6,0.4], [0.2,0.8], gamma=0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d13f66",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________\n",
    "### 6. Graph + state ops glue\n",
    "\n",
    "The graph + state glue coordinates the low-level temporal storage and the lightweight stateful primitives so they behave as a cohesive runtime. `ConversationRuntime` in this notebook acts as a small orchestrator: it maintains the temporal `DiGraph` of event histories, a per-user `ExpSmoother` instance to track inter-message statistics, and convenience methods to ingest messages, record ABANDON observations, run pause checks, and apply readiness updates. \n",
    "\n",
    "The runtime keeps concerns separated storage (graph), smoothing/statistics (smoothers), and decision rules (abandon/readiness) which makes it easier to test and replace individual components.\n",
    "\n",
    "Key operational patterns: when a message is ingested, the runtime appends a lightweight event to the appropriate temporal edge and updates the sender's smoother with the observed $\\Delta t$. Observing an abandon produces an append-only event on the edge (preserving history) rather than mutating aggregated state. \n",
    "\n",
    "Readiness updates are computed using the prior stored in the user's `UserContext` and then written back, so downstream code always reads a normalized distribution. \n",
    "\n",
    "This design supports auditability and deterministic replay: because events are append-only and timestamped, you can re-run offline analyses with alternative decay kernels or thresholds without losing the raw timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a20b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T03:54:06.792304Z",
     "iopub.status.busy": "2025-12-18T03:54:06.792046Z",
     "iopub.status.idle": "2025-12-18T03:54:06.801346Z",
     "shell.execute_reply": "2025-12-18T03:54:06.800220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed abandon, latest weight -> 0.2\n"
     ]
    }
   ],
   "source": [
    "class ConversationRuntime:\n",
    "    def __init__(self, alpha_smooth=0.2):\n",
    "        self.G = make_temporal_graph()\n",
    "        self.smoothers = {}  # user_id -> ExpSmoother\n",
    "        self.alpha_smooth = alpha_smooth\n",
    "\n",
    "    def get_smoother(self, user_id: str) -> ExpSmoother:\n",
    "        if user_id not in self.smoothers:\n",
    "            self.smoothers[user_id] = ExpSmoother(alpha=self.alpha_smooth)\n",
    "        return self.smoothers[user_id]\n",
    "\n",
    "    def ingest_message(self, msg: Message):\n",
    "        add_event_edge(self.G, msg.sender, msg.recipient or '__channel__', ts=msg.ts, weight=0.0, message_id=msg.id)\n",
    "        s = self.get_smoother(msg.sender)\n",
    "        last_ts = msg.metadata.get('prev_ts') if msg.metadata else None\n",
    "        if last_ts is not None:\n",
    "            delta = msg.ts - last_ts\n",
    "            s.update(delta)\n",
    "\n",
    "    def observe_abandon(self, src: str, dst: str, p_reply: float, alpha: float, ts: float):\n",
    "        return apply_abandon_increment(self.G, src, dst, alpha=alpha, p_reply=p_reply, ts=ts)\n",
    "\n",
    "    def check_pause(self, user_id: str, delta_t: float, k: float = 2.0) -> bool:\n",
    "        s = self.get_smoother(user_id)\n",
    "        return detect_pause(delta_t, s, k=k)\n",
    "\n",
    "    def apply_readiness_update(self, user_ctx: UserContext, likelihood: Sequence[float], gamma: float = 0.9):\n",
    "        new_ready = update_readiness(user_ctx.readiness, likelihood, gamma)\n",
    "        user_ctx.readiness = new_ready\n",
    "        return new_ready\n",
    "\n",
    "# small runtime demonstration\n",
    "rt = ConversationRuntime()\n",
    "rt.observe_abandon('user1','bot', p_reply=0.6, alpha=0.5, ts=2.0)\n",
    "print('observed abandon, latest weight ->', edge_weight_at(rt.G,'user1','bot'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b657719b",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________\n",
    "### 6. Deterministic unit tests\n",
    "\n",
    "A compact test harness validates core invariants (ABANDON increments, pause detection, readiness normalization). The tests are deterministic when the notebook sets fixed seeds or uses fixed inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e3835fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T03:54:06.804652Z",
     "iopub.status.busy": "2025-12-18T03:54:06.804413Z",
     "iopub.status.idle": "2025-12-18T03:54:06.812529Z",
     "shell.execute_reply": "2025-12-18T03:54:06.811327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All deterministic core-state tests passed\n"
     ]
    }
   ],
   "source": [
    "def _run_tests():\n",
    "    import math, traceback\n",
    "    try:\n",
    "        # ABANDON increment test\n",
    "        Gt = make_temporal_graph()\n",
    "        add_event_edge(Gt, 'u1', 'bot', ts=0.0, weight=0.2)\n",
    "        wb, wa = apply_abandon_increment(Gt, 'u1', 'bot', alpha=0.5, p_reply=0.6, ts=1.0)\n",
    "        assert math.isclose(wb, 0.2, rel_tol=1e-9), f'wb mismatch {wb}'\n",
    "        assert math.isclose(wa, 0.4, rel_tol=1e-9), f'wa mismatch {wa}'\n",
    "        # Pause detection test\n",
    "        s = ExpSmoother(alpha=0.2)\n",
    "        for x in [0.5, 0.6, 0.55, 0.45]:\n",
    "            s.update(x)\n",
    "        if not detect_pause(10.0, s, k=2.0):\n",
    "            raise AssertionError(f'Pause detection failed: mean={s.mean}, std={s.std}')\n",
    "        # readiness update test\n",
    "        new_pi = update_readiness([0.6,0.4], [0.2,0.8], gamma=0.8)\n",
    "        assert len(new_pi) == 2 and abs(sum(new_pi)-1.0) < 1e-9 and new_pi[1] > new_pi[0], f'readiness unexpected {new_pi}'\n",
    "        print('All deterministic core-state tests passed')\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "_run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb948f33",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________\n",
    "### 6. Worked example / walkthrough\n",
    "\n",
    "A short deterministic example that shows the runtime primitives interacting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4296761a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T03:54:06.816082Z",
     "iopub.status.busy": "2025-12-18T03:54:06.815509Z",
     "iopub.status.idle": "2025-12-18T03:54:06.823758Z",
     "shell.execute_reply": "2025-12-18T03:54:06.822529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weight @0.0 -> 0.2\n",
      "ABANDON: w_before= 0.2 w_after= 0.4\n",
      "Smoother mean, std -> 0.5108 0.0454\n",
      "Pause triggered for Δt=10.0 ? -> True\n",
      "readiness before -> [0.7, 0.3]\n",
      "readiness after -> [0.3394, 0.6606]\n"
     ]
    }
   ],
   "source": [
    "# Worked example prints\n",
    "Gx = make_temporal_graph()\n",
    "add_event_edge(Gx, 'user1', 'bot', ts=0.0, weight=0.2)\n",
    "print('Initial weight @0.0 ->', edge_weight_at(Gx, 'user1', 'bot', ts=0.0))\n",
    "wb, wa = apply_abandon_increment(Gx, 'user1', 'bot', alpha=0.5, p_reply=0.6, ts=1.0)\n",
    "print('ABANDON: w_before=', wb, 'w_after=', wa)\n",
    "s = ExpSmoother(alpha=0.2)\n",
    "for d in [0.5,0.6,0.55,0.45]:\n",
    "    s.update(d)\n",
    "print('Smoother mean, std ->', round(s.mean, 4), round(s.std, 4))\n",
    "print('Pause triggered for Δt=10.0 ? ->', detect_pause(10.0, s, k=2.0))\n",
    "ctx = UserContext(user_id='user1', last_seen_ts=1.0, readiness=[0.7,0.3])\n",
    "print('readiness before ->', ctx.readiness)\n",
    "ctx.readiness = update_readiness(ctx.readiness, [0.2,0.8], gamma=0.85)\n",
    "print('readiness after ->', [round(x,4) for x in ctx.readiness])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e61908",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________\n",
    "### 7. Artifact writer\n",
    "\n",
    "Export canonical JSON schemas for `Message` and `UserContext` so downstream notebooks and systems can validate inputs against a stable contract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d326874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T03:54:06.827028Z",
     "iopub.status.busy": "2025-12-18T03:54:06.826781Z",
     "iopub.status.idle": "2025-12-18T03:54:06.844710Z",
     "shell.execute_reply": "2025-12-18T03:54:06.843591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote artifact -> artifacts\\state_schema.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADITI\\AppData\\Local\\Temp\\ipykernel_9744\\729319765.py:2: PydanticDeprecatedSince20: The `schema_json` method is deprecated; use `model_json_schema` and json.dumps instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  'Message': json.loads(Message.schema_json()),\n",
      "C:\\Users\\ADITI\\AppData\\Local\\Temp\\ipykernel_9744\\729319765.py:3: PydanticDeprecatedSince20: The `schema_json` method is deprecated; use `model_json_schema` and json.dumps instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  'UserContext': json.loads(UserContext.schema_json()),\n"
     ]
    }
   ],
   "source": [
    "schema = {\n",
    "    'Message': json.loads(Message.schema_json()),\n",
    "    'UserContext': json.loads(UserContext.schema_json()),\n",
    "}\n",
    "with open(ARTIFACTS / 'state_schema.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(schema, f, indent=2)\n",
    "print('Wrote artifact ->', ARTIFACTS / 'state_schema.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212762b",
   "metadata": {},
   "source": [
    "**JSON preview: artifacts/state_schema.json**\n",
    "\n",
    "Load and pretty-print the generated schema to verify its contents.\n",
    "________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f693302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T03:54:06.848379Z",
     "iopub.status.busy": "2025-12-18T03:54:06.848115Z",
     "iopub.status.idle": "2025-12-18T03:54:06.858325Z",
     "shell.execute_reply": "2025-12-18T03:54:06.857397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading artifacts\\state_schema.json\n",
      "{'Message': {'$defs': {'EmotionalState': {'enum': ['neutral', 'positive', 'negative', 'frustrated', 'engaged'],\n",
      "                                          'title': 'EmotionalState',\n",
      "                                          'type': 'string'},\n",
      "                       'IntentClarity': {'enum': ['clear', 'ambiguous', 'unknown'],\n",
      "                                         'title': 'IntentClarity',\n",
      "                                         'type': 'string'}},\n",
      "             'properties': {'emotional_state': {'anyOf': [{'$ref': '#/$defs/EmotionalState'}, {'type': 'null'}],\n",
      "                                                'default': 'neutral'},\n",
      "                            'id': {'description': 'Unique message identifier', 'title': 'Id', 'type': 'string'},\n",
      "                            'intent_clarity': {'anyOf': [{'$ref': '#/$defs/IntentClarity'}, {'type': 'null'}],\n",
      "                                               'default': 'unknown'},\n",
      "                            'metadata': {'anyOf': [{'additionalProperties': True, 'type': 'object'}, {'type': 'null'}],\n",
      "                                         'default': None,\n",
      "                                         'title': 'Metadata'},\n",
      "                            'recipient': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Recipient'},\n",
      "                            'sender': {'title': 'Sender', 'type': 'string'},\n",
      "                            'text': {'title': 'Text', 'type': 'string'},\n",
      "                            'ts': {'description': 'Timestamp in seconds (monotonic/epoch)',\n",
      "                                   'title': 'Ts',\n",
      "                                   'type': 'number'}},\n",
      "             'required': ['id', 'sender', 'recipient', 'text', 'ts'],\n",
      "             'title': 'Message',\n",
      "             'type': 'object'},\n",
      " 'UserContext': {'$defs': {'EmotionalState': {'enum': ['neutral', 'positive', 'negative', 'frustrated', 'engaged'],\n",
      "                                              'title': 'EmotionalState',\n",
      "                                              'type': 'string'},\n",
      "                           'IntentClarity': {'enum': ['clear', 'ambiguous', 'unknown'],\n",
      "                                             'title': 'IntentClarity',\n",
      "                                             'type': 'string'}},\n",
      "                 'properties': {'emotional_state': {'$ref': '#/$defs/EmotionalState', 'default': 'neutral'},\n",
      "                                'intent_clarity': {'$ref': '#/$defs/IntentClarity', 'default': 'unknown'},\n",
      "                                'last_seen_ts': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
      "                                                 'default': None,\n",
      "                                                 'title': 'Last Seen Ts'},\n",
      "                                'notes': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
      "                                          'default': None,\n",
      "                                          'title': 'Notes'},\n",
      "                                'readiness': {'anyOf': [{'items': {'type': 'number'}, 'type': 'array'},\n",
      "                                                        {'type': 'null'}],\n",
      "                                              'description': 'Normalized readiness distribution',\n",
      "                                              'title': 'Readiness'},\n",
      "                                'user_id': {'title': 'User Id', 'type': 'string'}},\n",
      "                 'required': ['user_id'],\n",
      "                 'title': 'UserContext',\n",
      "                 'type': 'object'}}\n",
      "\n",
      "--- JSON (compact) ---\n",
      "{\n",
      "  \"Message\": {\n",
      "    \"$defs\": {\n",
      "      \"EmotionalState\": {\n",
      "        \"enum\": [\n",
      "          \"neutral\",\n",
      "          \"positive\",\n",
      "          \"negative\",\n",
      "          \"frustrated\",\n",
      "          \"engaged\"\n",
      "        ],\n",
      "        \"title\": \"EmotionalState\",\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"IntentClarity\": {\n",
      "        \"enum\": [\n",
      "          \"clear\",\n",
      "          \"ambiguous\",\n",
      "          \"unknown\"\n",
      "        ],\n",
      "        \"title\": \"IntentClarity\",\n",
      "        \"type\": \"string\"\n",
      "      }\n",
      "    },\n",
      "    \"properties\": {\n",
      "      \"id\": {\n",
      "        \"description\": \"Unique message identifier\",\n",
      "        \"title\": \"Id\",\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"sender\": {\n",
      "        \"title\": \"Sender\",\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"recipient\": {\n",
      "        \"anyOf\": [\n",
      "          {\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"null\"\n",
      "          }\n",
      "        ],\n",
      "        \"title\": \"Recipient\"\n",
      "      },\n",
      "      \"text\": {\n",
      "        \"title\": \"Text\",\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"ts\": {\n",
      "        \"description\": \"Timestamp in seconds (monotonic/epoch)\",\n",
      "        \"title\": \"Ts\",\n",
      "        \"type\": \"number\"\n",
      "      },\n",
      "      \"emotional_state\": {\n",
      "        \"anyOf\": [\n",
      "          {\n",
      "            \"$ref\": \"#/$defs/EmotionalState\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"null\"\n",
      "          }\n",
      "        ],\n",
      "        \"default\": \"neutral\"\n",
      "      },\n",
      "      \"intent_clarity\": {\n",
      "        \"anyOf\": [\n",
      "          {\n",
      "            \"$ref\": \"#/$defs/IntentClarity\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"null\"\n",
      "          }\n",
      "        ],\n",
      "        \"default\": \"unknown\"\n",
      "      },\n",
      "      \"metadata\": {\n",
      "        \"anyOf\": [\n",
      "          {\n",
      "            \"additionalProperties\": true,\n",
      "            \"type\": \"object\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"null\"\n",
      "          }\n",
      "        ],\n",
      "        \"default\": null,\n",
      "        \"title\": \"Metadata\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"id\",\n",
      "      \"sender\",\n",
      "      \"recipient\",\n",
      "      \"text\",\n",
      "      \"ts\"\n",
      "    ],\n",
      "    \"title\": \"Message\",\n",
      "    \"type\": \"object\"\n",
      "  },\n",
      "  \"UserContext\": {\n",
      "    \"$defs\": {\n",
      "      \"EmotionalState\": {\n",
      "        \"enum\": [\n",
      "          \"neutral\",\n",
      "          \"positive\",\n",
      "          \"negative\",\n",
      "          \"frustrated\",\n",
      "          \"engaged\"\n",
      "        ],\n",
      "        \"title\": \"EmotionalState\",\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"IntentClarity\": {\n",
      "        \"enum\": [\n",
      "          \"clear\",\n",
      "          \"ambiguous\",\n",
      "          \"unknown\"\n",
      "        ],\n",
      "        \"title\": \"IntentClarity\",\n",
      "        \"type\": \"string\"\n",
      "      }\n",
      "    },\n",
      "    \"properties\": {\n",
      "      \"user_id\": {\n",
      "        \"title\": \"User Id\",\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"last_seen_ts\": {\n",
      "        \"anyOf\": [\n",
      "          {\n",
      "            \"type\": \"number\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"null\"\n",
      "          }\n",
      "        ],\n",
      "        \"default\": null,\n",
      "        \"title\": \"Last Seen Ts\"\n",
      "      },\n",
      "      \"readiness\": {\n",
      "        \"anyOf\": [\n",
      "          {\n",
      "            \"items\": {\n",
      "              \"type\": \"number\"\n",
      "            },\n",
      "            \"type\": \"array\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"null\"\n",
      "          }\n",
      "        ],\n",
      "        \"description\": \"Normalized readiness distribution\",\n",
      "        \"title\": \"Readiness\"\n",
      "      },\n",
      "      \"emotional_state\": {\n",
      "        \"$ref\": \"#/$defs/EmotionalState\",\n",
      "        \"default\": \"neutral\"\n",
      "      },\n",
      "      \"intent_clarity\": {\n",
      "        \"$ref\": \"#/$defs/IntentClarity\",\n",
      "        \"default\": \"unknown\"\n",
      "      },\n",
      "      \"notes\": {\n",
      "        \"anyOf\": [\n",
      "          {\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"null\"\n",
      "          }\n",
      "        ],\n",
      "        \"default\": null,\n",
      "        \"title\": \"Notes\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"user_id\"\n",
      "    ],\n",
      "    \"title\": \"UserContext\",\n",
      "    \"type\": \"object\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "p = ARTIFACTS / 'state_schema.json'\n",
    "print('Reading', p)\n",
    "with open(p, 'r', encoding='utf-8') as f:\n",
    "    schema = json.load(f)\n",
    "pprint(schema, width=120)\n",
    "print('\\n--- JSON (compact) ---')\n",
    "print(json.dumps(schema, indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
